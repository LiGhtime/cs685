{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read meta data\n",
    "import json\n",
    "\n",
    "# Function to read a .jsonl file\n",
    "def read_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Parse each line as JSON and append to the data list\n",
    "            data.append(json.loads(line))\n",
    "            # break\n",
    "    return data\n",
    "\n",
    "movies_meta_data = read_jsonl('../data/meta_Movies_and_TV.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "asin_dict = {}\n",
    "for line in movies_meta_data:\n",
    "    if line['title'] is not None:\n",
    "        asin_dict[line['parent_asin']] = [line['title']]\n",
    "    # asin_dict[line['parent_asin']] = [line['title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save asin_dict to json file\n",
    "json_file_asins = '../data/meta_asins.json'\n",
    "with open(json_file_asins, \"w\") as file:\n",
    "    json.dump(asin_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MISC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "test_tensor = torch.tensor([[1, 2, 3, 4, 5],\n",
    "        [6, 7, 8, 9, 10],\n",
    "        [11, 12, 13, 14, 15]], device='cuda:0') \n",
    "\n",
    "test_tensor[:, -1, None], test_tensor[..., -1, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth: Fast Gemma patching release 2024.4\n",
      "   \\\\   /|    GPU: Tesla T4. Max memory: 14.581 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.2.2. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = FALSE. Xformers = 0.0.25.post1. FA = False.\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextStreamer, GenerationConfig\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "max_seq_length = 4096 # 8192 | Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"../outputs/model_04242024_090830/\", # YOUR MODEL YOU USED FOR TRAINING\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<bos>Justified:', '<unk>')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([2, 58423, 8920, 235292]), tokenizer.decode(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# asins_small.json to be used for meta data matching\n",
    "json_file_asins = '../data/asins_small.json'\n",
    "with open(json_file_asins, \"r\") as file:\n",
    "    asin_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trie def here\n",
    "class TrieNode:\n",
    "    def __init__(self, id):\n",
    "        self.children = {}\n",
    "        self.node_value = id\n",
    "    \n",
    "class Trie:\n",
    "    def __init__(self, bos_token_id):\n",
    "        self.root = TrieNode(bos_token_id) # set start of sentence id as root node\n",
    "        self.pad_token_id = tokenizer.pad_token_id\n",
    "        self.pad_node = TrieNode(self.pad_token_id)\n",
    "        self.pad_node.children[self.pad_token_id] = self.pad_node\n",
    "    \n",
    "    def insert(self, input_ids_list):\n",
    "        node = self.root\n",
    "        for id in input_ids_list[1:]:\n",
    "            if id not in node.children:\n",
    "                node.children[id] = TrieNode(id)\n",
    "            node = node.children[id]\n",
    "        \n",
    "    def search_children(self, input_ids_list):\n",
    "        # search for the input_ids_list in the trie\n",
    "        # the path is presented in the input_ids_list\n",
    "        # return the last node in the path                  \n",
    "        # input_ids_list should always start with 2 (start of sentence id)\n",
    "        \n",
    "        node = self.root\n",
    "        traverse_depth = 0\n",
    "        if len(input_ids_list) == 1:\n",
    "            return node\n",
    "        for id in input_ids_list[1:]:\n",
    "            if id in node.children:\n",
    "                node = node.children[id]\n",
    "                traverse_depth += 1\n",
    "            else:\n",
    "                # if id == self.pad_token_id:\n",
    "                #     return self.pad_node\n",
    "                \n",
    "                raise ValueError(\"input_ids_list not found in the trie. Traverse failed at node: \", node.node_value, \n",
    "                                \" at depth: \", traverse_depth)\n",
    "        return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trie = Trie(tokenizer.bos_token_id)\n",
    "for key in asin_dict.keys():\n",
    "    movie_title = asin_dict[key][0]\n",
    "    \n",
    "    # tokenize movie title\n",
    "    inputs = tokenizer(movie_title, return_tensors=\"pt\")\n",
    "    # get the input ids\n",
    "    input_ids = inputs['input_ids'].tolist()\n",
    "    \n",
    "    # append end of sentence id at the end of the input_ids\n",
    "    input_ids[0].append(tokenizer.eos_token_id)\n",
    "    # print(\"input_ids: \", input_ids)\n",
    "    \n",
    "    # insert this input_ids as a path in the trie\n",
    "    for id in input_ids:\n",
    "        trie.insert(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: <__main__.TrieNode at 0x7f3fd3f59d50>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trie.search_children([2, 58423, 8920, 235292, 13316, 235248, 235274, 892, 41330, 235290, 1040, 235307]).children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5859e+01, -1.4076e-03, -6.6719e+00, -9.8750e+00, -9.3125e+00,\n",
       "         -1.5125e+01],\n",
       "        [-1.7875e+01,  0.0000e+00, -1.7625e+01, -1.9031e+01, -1.7969e+01,\n",
       "         -1.7312e+01],\n",
       "        [-1.4477e+01, -2.4399e-02, -5.9922e+00, -3.8828e+00, -6.8672e+00,\n",
       "         -1.3914e+01]], device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "next_token_logits = torch.tensor([[-29.2969, -13.4375, -20.1094, -23.3125, -22.7500, -28.5625],\n",
    "        [-30.3125, -12.4453, -30.0625, -31.4688, -30.4219, -29.7500],\n",
    "        [-27.1094, -12.6562, -18.6250, -16.5156, -19.5000, -26.5469]],\n",
    "       device='cuda:0', dtype=torch.float16)\n",
    "next_token_scores = torch.nn.functional.log_softmax(next_token_logits, dim=-1)\n",
    "next_token_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2, 2, 2, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "test_token_scores = torch.tensor([1.3, 2.1, 3.4, -torch.inf, -torch.inf, -torch.inf])\n",
    "test_token_scores = torch.nn.functional.softmax(test_token_scores, dim=-1)\n",
    "torch.multinomial(test_token_scores, num_samples=6, replacement=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

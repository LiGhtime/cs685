[
    {
        "loss": 3.3952,
        "grad_norm": 2.012516975402832,
        "learning_rate": 4e-05,
        "epoch": 0.00012858428700012858,
        "step": 1
    },
    {
        "loss": 4.0747,
        "grad_norm": 3.359469175338745,
        "learning_rate": 8e-05,
        "epoch": 0.00025716857400025716,
        "step": 2
    },
    {
        "loss": 4.2761,
        "grad_norm": 3.7256548404693604,
        "learning_rate": 0.00012,
        "epoch": 0.00038575286100038574,
        "step": 3
    },
    {
        "loss": 3.9522,
        "grad_norm": 2.6807968616485596,
        "learning_rate": 0.00016,
        "epoch": 0.0005143371480005143,
        "step": 4
    },
    {
        "loss": 3.2705,
        "grad_norm": 2.327883720397949,
        "learning_rate": 0.0002,
        "epoch": 0.0006429214350006429,
        "step": 5
    },
    {
        "loss": 3.359,
        "grad_norm": 2.3851065635681152,
        "learning_rate": 0.00019994532573409262,
        "epoch": 0.0007715057220007715,
        "step": 6
    },
    {
        "loss": 3.5285,
        "grad_norm": 1.6207945346832275,
        "learning_rate": 0.00019978136272187747,
        "epoch": 0.0009000900090009,
        "step": 7
    },
    {
        "loss": 2.9188,
        "grad_norm": 3.6568520069122314,
        "learning_rate": 0.00019950829025450114,
        "epoch": 0.0010286742960010286,
        "step": 8
    },
    {
        "loss": 2.8878,
        "grad_norm": 3.426856517791748,
        "learning_rate": 0.00019912640693269752,
        "epoch": 0.0011572585830011573,
        "step": 9
    },
    {
        "loss": 3.0919,
        "grad_norm": 2.2305400371551514,
        "learning_rate": 0.00019863613034027224,
        "epoch": 0.0012858428700012858,
        "step": 10
    },
    {
        "eval_loss": 2.884901762008667,
        "eval_runtime": 29.6301,
        "eval_samples_per_second": 2.666,
        "eval_steps_per_second": 2.666,
        "epoch": 0.0012858428700012858,
        "step": 10
    },
    {
        "loss": 2.7837,
        "grad_norm": 2.0278806686401367,
        "learning_rate": 0.00019803799658748094,
        "epoch": 0.0014144271570014145,
        "step": 11
    },
    {
        "loss": 3.0506,
        "grad_norm": 2.00285267829895,
        "learning_rate": 0.0001973326597248006,
        "epoch": 0.001543011444001543,
        "step": 12
    },
    {
        "loss": 2.5345,
        "grad_norm": 1.6958755254745483,
        "learning_rate": 0.00019652089102773488,
        "epoch": 0.0016715957310016716,
        "step": 13
    },
    {
        "loss": 2.3923,
        "grad_norm": 2.1947991847991943,
        "learning_rate": 0.00019560357815343577,
        "epoch": 0.0018001800180018,
        "step": 14
    },
    {
        "loss": 2.7125,
        "grad_norm": 2.1976287364959717,
        "learning_rate": 0.00019458172417006347,
        "epoch": 0.0019287643050019288,
        "step": 15
    },
    {
        "loss": 2.8759,
        "grad_norm": 1.3689249753952026,
        "learning_rate": 0.0001934564464599461,
        "epoch": 0.0020573485920020573,
        "step": 16
    },
    {
        "loss": 2.717,
        "grad_norm": 1.8744219541549683,
        "learning_rate": 0.00019222897549773848,
        "epoch": 0.002185932879002186,
        "step": 17
    },
    {
        "loss": 2.4144,
        "grad_norm": 1.9120256900787354,
        "learning_rate": 0.00019090065350491626,
        "epoch": 0.0023145171660023146,
        "step": 18
    },
    {
        "loss": 2.3379,
        "grad_norm": 2.228641986846924,
        "learning_rate": 0.00018947293298207635,
        "epoch": 0.002443101453002443,
        "step": 19
    },
    {
        "loss": 2.6921,
        "grad_norm": 1.932558536529541,
        "learning_rate": 0.0001879473751206489,
        "epoch": 0.0025716857400025716,
        "step": 20
    },
    {
        "eval_loss": 2.4669349193573,
        "eval_runtime": 27.8844,
        "eval_samples_per_second": 2.833,
        "eval_steps_per_second": 2.833,
        "epoch": 0.0025716857400025716,
        "step": 20
    },
    {
        "loss": 2.8405,
        "grad_norm": 1.401239275932312,
        "learning_rate": 0.00018632564809575742,
        "epoch": 0.0027002700270027003,
        "step": 21
    },
    {
        "loss": 2.4532,
        "grad_norm": 1.2982261180877686,
        "learning_rate": 0.00018460952524209355,
        "epoch": 0.002828854314002829,
        "step": 22
    },
    {
        "loss": 2.1621,
        "grad_norm": 1.9031566381454468,
        "learning_rate": 0.00018280088311480201,
        "epoch": 0.0029574386010029576,
        "step": 23
    },
    {
        "loss": 2.752,
        "grad_norm": 1.3638325929641724,
        "learning_rate": 0.00018090169943749476,
        "epoch": 0.003086022888003086,
        "step": 24
    },
    {
        "loss": 2.253,
        "grad_norm": 1.8858476877212524,
        "learning_rate": 0.00017891405093963938,
        "epoch": 0.0032146071750032146,
        "step": 25
    },
    {
        "loss": 2.5753,
        "grad_norm": 1.8403995037078857,
        "learning_rate": 0.00017684011108568592,
        "epoch": 0.0033431914620033433,
        "step": 26
    },
    {
        "loss": 2.3703,
        "grad_norm": 1.3479504585266113,
        "learning_rate": 0.0001746821476984154,
        "epoch": 0.003471775749003472,
        "step": 27
    },
    {
        "loss": 1.8182,
        "grad_norm": 2.3796348571777344,
        "learning_rate": 0.00017244252047910892,
        "epoch": 0.0036003600360036,
        "step": 28
    },
    {
        "loss": 2.7487,
        "grad_norm": 1.372633695602417,
        "learning_rate": 0.00017012367842724887,
        "epoch": 0.003728944323003729,
        "step": 29
    },
    {
        "loss": 1.818,
        "grad_norm": 2.227484703063965,
        "learning_rate": 0.00016772815716257412,
        "epoch": 0.0038575286100038576,
        "step": 30
    },
    {
        "eval_loss": 2.363816022872925,
        "eval_runtime": 28.3722,
        "eval_samples_per_second": 2.784,
        "eval_steps_per_second": 2.784,
        "epoch": 0.0038575286100038576,
        "step": 30
    },
    {
        "loss": 2.0687,
        "grad_norm": 2.22520112991333,
        "learning_rate": 0.00016525857615241687,
        "epoch": 0.003986112897003986,
        "step": 31
    },
    {
        "loss": 2.8057,
        "grad_norm": 1.568925380706787,
        "learning_rate": 0.0001627176358473537,
        "epoch": 0.0041146971840041145,
        "step": 32
    },
    {
        "loss": 2.7547,
        "grad_norm": 1.1879849433898926,
        "learning_rate": 0.00016010811472830252,
        "epoch": 0.004243281471004243,
        "step": 33
    },
    {
        "loss": 1.9523,
        "grad_norm": 2.0459585189819336,
        "learning_rate": 0.00015743286626829437,
        "epoch": 0.004371865758004372,
        "step": 34
    },
    {
        "loss": 2.3576,
        "grad_norm": 1.7000722885131836,
        "learning_rate": 0.00015469481581224272,
        "epoch": 0.004500450045004501,
        "step": 35
    },
    {
        "loss": 2.4567,
        "grad_norm": 1.864172101020813,
        "learning_rate": 0.00015189695737812152,
        "epoch": 0.004629034332004629,
        "step": 36
    },
    {
        "loss": 2.0213,
        "grad_norm": 2.049482822418213,
        "learning_rate": 0.00014904235038305083,
        "epoch": 0.004757618619004758,
        "step": 37
    },
    {
        "loss": 2.6075,
        "grad_norm": 1.7894335985183716,
        "learning_rate": 0.0001461341162978688,
        "epoch": 0.004886202906004886,
        "step": 38
    },
    {
        "loss": 2.0013,
        "grad_norm": 2.5467231273651123,
        "learning_rate": 0.00014317543523384928,
        "epoch": 0.0050147871930050145,
        "step": 39
    },
    {
        "loss": 2.4111,
        "grad_norm": 1.5843199491500854,
        "learning_rate": 0.00014016954246529696,
        "epoch": 0.005143371480005143,
        "step": 40
    },
    {
        "eval_loss": 2.3164823055267334,
        "eval_runtime": 28.0678,
        "eval_samples_per_second": 2.815,
        "eval_steps_per_second": 2.815,
        "epoch": 0.005143371480005143,
        "step": 40
    },
    {
        "loss": 2.2641,
        "grad_norm": 1.7828521728515625,
        "learning_rate": 0.00013711972489182208,
        "epoch": 0.005271955767005272,
        "step": 41
    },
    {
        "loss": 2.8395,
        "grad_norm": 1.4393364191055298,
        "learning_rate": 0.00013402931744416433,
        "epoch": 0.0054005400540054005,
        "step": 42
    },
    {
        "loss": 2.0331,
        "grad_norm": 1.8038876056671143,
        "learning_rate": 0.00013090169943749476,
        "epoch": 0.005529124341005529,
        "step": 43
    },
    {
        "loss": 2.2844,
        "grad_norm": 2.0895190238952637,
        "learning_rate": 0.00012774029087618446,
        "epoch": 0.005657708628005658,
        "step": 44
    },
    {
        "loss": 2.6305,
        "grad_norm": 1.8466367721557617,
        "learning_rate": 0.00012454854871407994,
        "epoch": 0.005786292915005787,
        "step": 45
    },
    {
        "loss": 2.3239,
        "grad_norm": 1.3336864709854126,
        "learning_rate": 0.0001213299630743747,
        "epoch": 0.005914877202005915,
        "step": 46
    },
    {
        "loss": 2.4821,
        "grad_norm": 1.9930436611175537,
        "learning_rate": 0.000118088053433211,
        "epoch": 0.006043461489006043,
        "step": 47
    },
    {
        "loss": 2.4837,
        "grad_norm": 1.3877862691879272,
        "learning_rate": 0.0001148263647711842,
        "epoch": 0.006172045776006172,
        "step": 48
    },
    {
        "loss": 2.2924,
        "grad_norm": 1.777692437171936,
        "learning_rate": 0.00011154846369695863,
        "epoch": 0.0063006300630063005,
        "step": 49
    },
    {
        "loss": 2.544,
        "grad_norm": 1.7333905696868896,
        "learning_rate": 0.00010825793454723325,
        "epoch": 0.006429214350006429,
        "step": 50
    },
    {
        "eval_loss": 2.2985680103302,
        "eval_runtime": 28.2781,
        "eval_samples_per_second": 2.794,
        "eval_steps_per_second": 2.794,
        "epoch": 0.006429214350006429,
        "step": 50
    },
    {
        "loss": 1.4441,
        "grad_norm": 2.496988296508789,
        "learning_rate": 0.00010495837546732224,
        "epoch": 0.006557798637006558,
        "step": 51
    },
    {
        "loss": 2.7111,
        "grad_norm": 1.1866334676742554,
        "learning_rate": 0.00010165339447663587,
        "epoch": 0.0066863829240066865,
        "step": 52
    },
    {
        "loss": 2.1869,
        "grad_norm": 1.663725733757019,
        "learning_rate": 9.834660552336415e-05,
        "epoch": 0.006814967211006815,
        "step": 53
    },
    {
        "loss": 2.7626,
        "grad_norm": 1.1302083730697632,
        "learning_rate": 9.504162453267777e-05,
        "epoch": 0.006943551498006944,
        "step": 54
    },
    {
        "loss": 2.1436,
        "grad_norm": 1.5845807790756226,
        "learning_rate": 9.174206545276677e-05,
        "epoch": 0.007072135785007072,
        "step": 55
    },
    {
        "loss": 2.4777,
        "grad_norm": 1.7697445154190063,
        "learning_rate": 8.845153630304139e-05,
        "epoch": 0.0072007200720072,
        "step": 56
    },
    {
        "loss": 2.0753,
        "grad_norm": 1.8944180011749268,
        "learning_rate": 8.517363522881579e-05,
        "epoch": 0.007329304359007329,
        "step": 57
    },
    {
        "loss": 2.5442,
        "grad_norm": 1.3407180309295654,
        "learning_rate": 8.191194656678904e-05,
        "epoch": 0.007457888646007458,
        "step": 58
    },
    {
        "loss": 2.1142,
        "grad_norm": 2.643024206161499,
        "learning_rate": 7.867003692562534e-05,
        "epoch": 0.0075864729330075865,
        "step": 59
    },
    {
        "loss": 2.3588,
        "grad_norm": 1.6408437490463257,
        "learning_rate": 7.54514512859201e-05,
        "epoch": 0.007715057220007715,
        "step": 60
    },
    {
        "eval_loss": 2.2782866954803467,
        "eval_runtime": 28.257,
        "eval_samples_per_second": 2.796,
        "eval_steps_per_second": 2.796,
        "epoch": 0.007715057220007715,
        "step": 60
    },
    {
        "loss": 2.4108,
        "grad_norm": 1.94438898563385,
        "learning_rate": 7.225970912381556e-05,
        "epoch": 0.007843641507007844,
        "step": 61
    },
    {
        "loss": 2.3171,
        "grad_norm": 1.7946090698242188,
        "learning_rate": 6.909830056250527e-05,
        "epoch": 0.007972225794007972,
        "step": 62
    },
    {
        "loss": 2.5253,
        "grad_norm": 1.526562213897705,
        "learning_rate": 6.59706825558357e-05,
        "epoch": 0.008100810081008101,
        "step": 63
    },
    {
        "loss": 2.527,
        "grad_norm": 0.9428865313529968,
        "learning_rate": 6.28802751081779e-05,
        "epoch": 0.008229394368008229,
        "step": 64
    },
    {
        "loss": 2.5748,
        "grad_norm": 1.2811232805252075,
        "learning_rate": 5.983045753470308e-05,
        "epoch": 0.008357978655008359,
        "step": 65
    },
    {
        "loss": 2.5877,
        "grad_norm": 1.4105432033538818,
        "learning_rate": 5.6824564766150726e-05,
        "epoch": 0.008486562942008486,
        "step": 66
    },
    {
        "loss": 2.3336,
        "grad_norm": 1.8649877309799194,
        "learning_rate": 5.386588370213124e-05,
        "epoch": 0.008615147229008616,
        "step": 67
    },
    {
        "loss": 2.1947,
        "grad_norm": 1.387351393699646,
        "learning_rate": 5.095764961694922e-05,
        "epoch": 0.008743731516008744,
        "step": 68
    },
    {
        "loss": 2.5028,
        "grad_norm": 1.3225438594818115,
        "learning_rate": 4.810304262187852e-05,
        "epoch": 0.008872315803008872,
        "step": 69
    },
    {
        "loss": 2.2586,
        "grad_norm": 1.4688825607299805,
        "learning_rate": 4.530518418775733e-05,
        "epoch": 0.009000900090009001,
        "step": 70
    },
    {
        "eval_loss": 2.2674057483673096,
        "eval_runtime": 28.2217,
        "eval_samples_per_second": 2.799,
        "eval_steps_per_second": 2.799,
        "epoch": 0.009000900090009001,
        "step": 70
    },
    {
        "loss": 1.889,
        "grad_norm": 2.2550737857818604,
        "learning_rate": 4.256713373170564e-05,
        "epoch": 0.009129484377009129,
        "step": 71
    },
    {
        "loss": 1.7374,
        "grad_norm": 1.9893189668655396,
        "learning_rate": 3.9891885271697496e-05,
        "epoch": 0.009258068664009259,
        "step": 72
    },
    {
        "loss": 2.1083,
        "grad_norm": 2.419361114501953,
        "learning_rate": 3.7282364152646297e-05,
        "epoch": 0.009386652951009386,
        "step": 73
    },
    {
        "loss": 2.3949,
        "grad_norm": 1.6433379650115967,
        "learning_rate": 3.4741423847583134e-05,
        "epoch": 0.009515237238009516,
        "step": 74
    },
    {
        "loss": 2.3015,
        "grad_norm": 1.6927573680877686,
        "learning_rate": 3.227184283742591e-05,
        "epoch": 0.009643821525009644,
        "step": 75
    },
    {
        "loss": 2.6514,
        "grad_norm": 1.8343263864517212,
        "learning_rate": 2.9876321572751144e-05,
        "epoch": 0.009772405812009772,
        "step": 76
    },
    {
        "loss": 2.1534,
        "grad_norm": 2.1091885566711426,
        "learning_rate": 2.7557479520891104e-05,
        "epoch": 0.009900990099009901,
        "step": 77
    },
    {
        "loss": 1.4851,
        "grad_norm": 2.7731263637542725,
        "learning_rate": 2.5317852301584643e-05,
        "epoch": 0.010029574386010029,
        "step": 78
    },
    {
        "loss": 1.8992,
        "grad_norm": 2.0572142601013184,
        "learning_rate": 2.315988891431412e-05,
        "epoch": 0.010158158673010158,
        "step": 79
    },
    {
        "loss": 2.348,
        "grad_norm": 1.7093353271484375,
        "learning_rate": 2.1085949060360654e-05,
        "epoch": 0.010286742960010286,
        "step": 80
    },
    {
        "eval_loss": 2.2608511447906494,
        "eval_runtime": 28.2384,
        "eval_samples_per_second": 2.798,
        "eval_steps_per_second": 2.798,
        "epoch": 0.010286742960010286,
        "step": 80
    },
    {
        "loss": 2.7697,
        "grad_norm": 1.772170901298523,
        "learning_rate": 1.9098300562505266e-05,
        "epoch": 0.010415327247010416,
        "step": 81
    },
    {
        "loss": 2.8356,
        "grad_norm": 1.1133722066879272,
        "learning_rate": 1.7199116885197995e-05,
        "epoch": 0.010543911534010544,
        "step": 82
    },
    {
        "loss": 2.373,
        "grad_norm": 1.5512800216674805,
        "learning_rate": 1.5390474757906446e-05,
        "epoch": 0.010672495821010673,
        "step": 83
    },
    {
        "loss": 2.6362,
        "grad_norm": 1.6378836631774902,
        "learning_rate": 1.3674351904242611e-05,
        "epoch": 0.010801080108010801,
        "step": 84
    },
    {
        "loss": 2.2089,
        "grad_norm": 1.9442211389541626,
        "learning_rate": 1.2052624879351104e-05,
        "epoch": 0.010929664395010929,
        "step": 85
    },
    {
        "loss": 1.2876,
        "grad_norm": 2.2661566734313965,
        "learning_rate": 1.0527067017923654e-05,
        "epoch": 0.011058248682011058,
        "step": 86
    },
    {
        "loss": 2.2597,
        "grad_norm": 1.7301790714263916,
        "learning_rate": 9.09934649508375e-06,
        "epoch": 0.011186832969011186,
        "step": 87
    },
    {
        "loss": 2.2583,
        "grad_norm": 1.7475618124008179,
        "learning_rate": 7.771024502261526e-06,
        "epoch": 0.011315417256011316,
        "step": 88
    },
    {
        "loss": 2.6354,
        "grad_norm": 1.2032690048217773,
        "learning_rate": 6.543553540053926e-06,
        "epoch": 0.011444001543011444,
        "step": 89
    },
    {
        "loss": 2.0712,
        "grad_norm": 1.8335163593292236,
        "learning_rate": 5.418275829936537e-06,
        "epoch": 0.011572585830011573,
        "step": 90
    },
    {
        "eval_loss": 2.258448600769043,
        "eval_runtime": 28.1861,
        "eval_samples_per_second": 2.803,
        "eval_steps_per_second": 2.803,
        "epoch": 0.011572585830011573,
        "step": 90
    },
    {
        "loss": 2.27,
        "grad_norm": 1.6376674175262451,
        "learning_rate": 4.3964218465642355e-06,
        "epoch": 0.011701170117011701,
        "step": 91
    },
    {
        "loss": 2.1209,
        "grad_norm": 1.8445223569869995,
        "learning_rate": 3.4791089722651436e-06,
        "epoch": 0.01182975440401183,
        "step": 92
    },
    {
        "loss": 2.2304,
        "grad_norm": 1.3506932258605957,
        "learning_rate": 2.667340275199426e-06,
        "epoch": 0.011958338691011958,
        "step": 93
    },
    {
        "loss": 1.9057,
        "grad_norm": 2.2837562561035156,
        "learning_rate": 1.9620034125190644e-06,
        "epoch": 0.012086922978012086,
        "step": 94
    },
    {
        "loss": 2.7767,
        "grad_norm": 1.4199717044830322,
        "learning_rate": 1.3638696597277679e-06,
        "epoch": 0.012215507265012216,
        "step": 95
    },
    {
        "loss": 2.2873,
        "grad_norm": 1.6282658576965332,
        "learning_rate": 8.735930673024806e-07,
        "epoch": 0.012344091552012344,
        "step": 96
    },
    {
        "loss": 2.0212,
        "grad_norm": 2.3151700496673584,
        "learning_rate": 4.917097454988584e-07,
        "epoch": 0.012472675839012473,
        "step": 97
    },
    {
        "loss": 2.2065,
        "grad_norm": 1.345738410949707,
        "learning_rate": 2.1863727812254653e-07,
        "epoch": 0.012601260126012601,
        "step": 98
    },
    {
        "loss": 2.4978,
        "grad_norm": 1.8487482070922852,
        "learning_rate": 5.467426590739511e-08,
        "epoch": 0.01272984441301273,
        "step": 99
    },
    {
        "loss": 2.0868,
        "grad_norm": 1.3511831760406494,
        "learning_rate": 0.0,
        "epoch": 0.012858428700012858,
        "step": 100
    },
    {
        "eval_loss": 2.2578330039978027,
        "eval_runtime": 28.9981,
        "eval_samples_per_second": 2.724,
        "eval_steps_per_second": 2.724,
        "epoch": 0.012858428700012858,
        "step": 100
    },
    {
        "train_runtime": 496.1184,
        "train_samples_per_second": 0.403,
        "train_steps_per_second": 0.202,
        "total_flos": 2709255688396800.0,
        "train_loss": 2.464292610883713,
        "epoch": 0.012858428700012858,
        "step": 100
    }
]
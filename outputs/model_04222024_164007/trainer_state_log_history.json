[
    {
        "loss": 2.9013,
        "grad_norm": 1.994632601737976,
        "learning_rate": 4e-05,
        "epoch": 0.0001288410745345616,
        "step": 1
    },
    {
        "loss": 2.7872,
        "grad_norm": 1.686665654182434,
        "learning_rate": 8e-05,
        "epoch": 0.0002576821490691232,
        "step": 2
    },
    {
        "loss": 3.2262,
        "grad_norm": 1.9975616931915283,
        "learning_rate": 0.00012,
        "epoch": 0.00038652322360368483,
        "step": 3
    },
    {
        "loss": 2.7484,
        "grad_norm": 2.3515565395355225,
        "learning_rate": 0.00016,
        "epoch": 0.0005153642981382464,
        "step": 4
    },
    {
        "loss": 2.9331,
        "grad_norm": 1.6446375846862793,
        "learning_rate": 0.0002,
        "epoch": 0.0006442053726728081,
        "step": 5
    },
    {
        "loss": 2.4395,
        "grad_norm": 1.7633520364761353,
        "learning_rate": 0.00018090169943749476,
        "epoch": 0.0007730464472073697,
        "step": 6
    },
    {
        "loss": 2.8732,
        "grad_norm": 1.6931666135787964,
        "learning_rate": 0.00013090169943749476,
        "epoch": 0.0009018875217419313,
        "step": 7
    },
    {
        "loss": 2.8856,
        "grad_norm": 1.8168097734451294,
        "learning_rate": 6.909830056250527e-05,
        "epoch": 0.0010307285962764929,
        "step": 8
    },
    {
        "loss": 2.9077,
        "grad_norm": 1.7584558725357056,
        "learning_rate": 1.9098300562505266e-05,
        "epoch": 0.0011595696708110545,
        "step": 9
    },
    {
        "loss": 2.5403,
        "grad_norm": 2.370713949203491,
        "learning_rate": 0.0,
        "epoch": 0.0012884107453456162,
        "step": 10
    },
    {
        "train_runtime": 26.3451,
        "train_samples_per_second": 0.759,
        "train_steps_per_second": 0.38,
        "total_flos": 342027113902080.0,
        "train_loss": 2.8242294549942017,
        "epoch": 0.0012884107453456162,
        "step": 10
    }
]
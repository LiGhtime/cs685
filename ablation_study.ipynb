{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. About the effectiveness of user intention\n",
    "\n",
    "We have a model trained without user intention, and we have a model trained with user intention. The later one got better mean Reciprocal Rank. The following cells try to show if we add user intention to the previous model in test time, would there be any improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the prediction results dict from the no intention model\n",
    "import json\n",
    "\n",
    "def read_json(file):\n",
    "    with open(file, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "results_dict = read_json('./eval_results/eval_051624_151124/predictions.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the full training data, which has intention paired with ground truth movie title\n",
    "full_data = read_json('./data/gemma_chat_training_wo_description_fixed_empty_string_filter.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the previous historical purchases and reviews of the user:\n",
      "```\n",
      "Item title: One Step Behind \n",
      " Item description: A dangerous man awakes in the care of a mysterious woman. Once the pieces of his past fall into place, he's faced with the stark choice of accepting his new found love or becoming the man he once was. \n",
      " rating: 4.0 \n",
      " review: Nice Hard Boiled Indie! Plenty of Bad Guys, Femme Fatales and one Big Bad Ass Reluctant Hero! If you like old school Film Noir -  more specifically Hard Boiled - you'll enjoy this little indie film. It reminded me a lot of the Coen Brother's BLOOD SIMPLE and another desert noir from the 90s starring Nick Cage RED ROCK WEST. It has that same pace and flavor to it and it pays of at the end. Well done!-------\n",
      "Item title: Untouched \n",
      " Item description: This legal drama explores the life-changing effects a secret abortion has on Mitch Thomas. A town startled by an infant found murdered in a dumpster, stirs Mitch, the reluctant attorney, conflicted by the love he lost, to unveil his haunting secret. \n",
      " rating: 4.0 \n",
      " review: Nice courtroom drama with it's heart in the right place. Beautifully shot and written, this is an intriguing story with a bittersweet ending. Really enjoyed it!-------\n",
      "Item title: The Man In The Silo \n",
      " Item description: A successful business man wakes up to find himself in a dilapidated grain silo, he must reconnect the dots of his traumatized memory to discover the truth of how he ended up there. \n",
      " rating: 5.0 \n",
      " review: This is a beautiful film full of great cinematic storytelling plus a classic re-hash of the Bernard Herman's Vertigo Score. Being a Hitchcock fan, I can honestly say that this is a true HITCHCOCKIAN film - which we hear a lot but hardly ever see. You can tell the film was made with so much attention to detail and passion by the great cinematography, transitions, acting, pace, acting and editing - and everything works together to achieve a great visual art piece. But don't get me wrong, it is also super exciting and entertaining as the film keeps you guessing from beginning to end. It is full of intrigue and suspense - and it is haunting. I highly recommend THE MAN IN THE SILO and I can almost guarantee you haven't seen anything like it!-------\n",
      "```\n",
      "And here is the user's intention: I really enjoy indie films with strong storytelling and emotional depth, so I'm looking for a movie that will steal my heart and make me want to fall in love all over again.\n",
      "Please infer the user's preference based on historical purchases and reviews along with the user's intention, and then recommend an item for this user. Please just give the title of the recommended item.\n",
      "A Night Without Armor\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(full_data)):\n",
    "    print(full_data[\"input\"][i])\n",
    "    print(full_data[\"output\"][i])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Below is the previous historical purchases and reviews of the user:\\n```\\nItem title: The Gathering \\n Item description: Product Description Gathering, The (1976 TVM) (DVD) Edward Asner and Maureen Stapleton star in this poignant and heartwarming story of the reconciliation between a successful businessman and the family he long ago abandoned to pursue a career. When Adam Thornton (Asner) learns that he is terminally ill, his estranged wife (Stapleton) insists that he spend one last Christmas with his now-adult children. Adam agrees--but insists that they not know of his illness. Now, in an idyllic, snow-covered New England town, the Thornton family tries to find reunion before it is too late. ]]> Amazon.com A fondly remembered holiday item from the latter phase of a great age of TV movies, The Gathering has an irresistible idea and a splendid central performance from Edward Asner, the actor for whom the term gruff but lovable was surely coined. We learn in the opening seconds of the film that Asner's character, a well-to-do businessman named Adam Thornton, has been diagnosed with a terminal illness; he's got three months left, at best. Time to make amends, and Adam reaches out to his ex-wife (Maureen Stapleton) and his mostly estranged kids for a final Christmas gathering. You won't find many surprises along the way, but the script by veteran screenwriter James Poe takes time for the small things, and gives Asner a believably conflicted character to play. It's directed by Randal Kleiser, who was just a year away from jumping to a big-screen career and scoring a smash with Grease . There's also some interest in watching a batch of young actors in the early stages of their careers: Bruce Davison, Gregory Harrison, Veronica Hamel, and Stephanie Zimbalist are in the Thornton extended family. If The Gathering has the basic look and feel of a TV movie (with wintry location work in Ohio), it nevertheless creates an honest, earned glow as it sorts through one man's final accounting of what has mattered in his life. --Robert Horton \\n rating: 5.0 \\n review: This version is an OFFICIAL release by MGM studios with closed captioning.<br /><br />Yes the movie looks a little dated, the clothes, the cars, etc...but that's just the external stuff.<br /><br />The story itself is timeless.<br /><br />It's nice to finally have on dvd with captions.  Thanks MGM and Amazon.-------\\nItem title: 84 Charing Cross Road \\n Item description: An American writer forms an enduring relationship with a London bookseller which is carried on over 20 years and across two continents. Genre: Feature Film-Drama Rating: PG Release Date: 23-SEP-2003 Media Type: DVD \\n rating: 5.0 \\n review: I bought the book because of  this movie.  Even when I read it I hear the voices of the these two wonderful actors.-------\\n```\\nAnd here is the user's intention: I enjoy heartwarming stories and dramas with strong character development, so I'd love a recommendation for a movie that has a compelling storyline and well-defined characters.\\nPlease infer the user's preference based on historical purchases and reviews along with the user's intention, and then recommend an item for this user. Please just give the title of the recommended item.\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_full_intention(full_data, movie_title):\n",
    "    for i in range(len(full_data[\"input\"])):\n",
    "        if full_data[\"output\"][i] == movie_title:\n",
    "            return full_data[\"input\"][i]\n",
    "    return None\n",
    "\n",
    "find_full_intention(full_data, \"La Femme Nikita: The Complete Second Season\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each instance in results dict, get the intention\n",
    "for instance in results_dict:\n",
    "    # print(results_dict[instance].keys())\n",
    "    movie_title = results_dict[instance]['ground_truth']\n",
    "    # find full intention prompt in full_data, based on movie title\n",
    "    # full_data[\"input\"][i] is the prompt, full_data[\"output\"][i] is the movie title\n",
    "    for i in range(len(full_data[\"input\"])):\n",
    "        if full_data[\"output\"][i] == movie_title:\n",
    "            print(full_data[\"input\"][i])\n",
    "            break\n",
    "    \n",
    "    print('-----------------')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth: Fast Gemma patching release 2024.4\n",
      "   \\\\   /|    GPU: Tesla T4. Max memory: 14.581 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.2.2. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = FALSE. Xformers = 0.0.25.post1. FA = False.\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using customized constraint logits processor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating trie...\n",
      "new_token_input_ids_list[0]: [2]\n",
      "new_token_input_ids_list[0]: [2]\n",
      "new_token_input_ids_list[0]: [2]\n",
      "new_token_input_ids_list[0]: [2]\n",
      "new_token_input_ids_list[0]: [2]\n",
      "new_token_input_ids_list[0]: [2, 651]\n",
      "new_token_input_ids_list[0]: [2, 651]\n",
      "new_token_input_ids_list[0]: [2, 74268]\n",
      "new_token_input_ids_list[0]: [2, 651]\n",
      "new_token_input_ids_list[0]: [2, 188729]\n",
      "new_token_input_ids_list[0]: [2, 651, 165609]\n",
      "new_token_input_ids_list[0]: [2, 651, 140994]\n",
      "new_token_input_ids_list[0]: [2, 74268, 591]\n",
      "new_token_input_ids_list[0]: [2, 651, 8182]\n",
      "new_token_input_ids_list[0]: [2, 188729, 576]\n",
      "new_token_input_ids_list[0]: [2, 651, 165609, 235292]\n",
      "new_token_input_ids_list[0]: [2, 651, 140994, 0]\n",
      "new_token_input_ids_list[0]: [2, 74268, 591, 12905]\n",
      "new_token_input_ids_list[0]: [2, 651, 8182, 6251]\n",
      "new_token_input_ids_list[0]: [2, 188729, 576, 573]\n",
      "new_token_input_ids_list[0]: [2, 651, 165609, 235292, 714]\n",
      "new_token_input_ids_list[0]: [2, 651, 140994, 0, 0]\n",
      "new_token_input_ids_list[0]: [2, 74268, 591, 12905, 235275]\n",
      "new_token_input_ids_list[0]: [2, 651, 8182, 6251, 576]\n",
      "new_token_input_ids_list[0]: [2, 188729, 576, 573, 33336]\n",
      "new_token_input_ids_list[0]: [2, 651, 165609, 235292, 714, 18949]\n",
      "new_token_input_ids_list[0]: [2, 651, 140994, 0, 0, 0]\n",
      "new_token_input_ids_list[0]: [2, 74268, 591, 12905, 235275, 892]\n",
      "new_token_input_ids_list[0]: [2, 651, 8182, 6251, 576, 56635]\n",
      "new_token_input_ids_list[0]: [2, 188729, 576, 573, 33336, 235292]\n",
      "new_token_input_ids_list[0]: [2, 651, 165609, 235292, 714, 18949, 576]\n",
      "new_token_input_ids_list[0]: [2, 651, 140994, 0, 0, 0, 0]\n",
      "new_token_input_ids_list[0]: [2, 74268, 591, 12905, 235275, 892, 41330]\n",
      "new_token_input_ids_list[0]: [2, 651, 8182, 6251, 576, 56635, 892]\n",
      "new_token_input_ids_list[0]: [2, 188729, 576, 573, 33336, 235292, 1993]\n",
      "new_token_input_ids_list[0]: [2, 651, 165609, 235292, 714, 18949, 576, 573]\n",
      "new_token_input_ids_list[0]: [2, 651, 140994, 0, 0, 0, 0, 0]\n",
      "new_token_input_ids_list[0]: [2, 74268, 591, 12905, 235275, 892, 41330, 235290]\n",
      "new_token_input_ids_list[0]: [2, 651, 8182, 6251, 576, 56635, 892, 41330]\n",
      "new_token_input_ids_list[0]: [2, 188729, 576, 573, 33336, 235292, 1993, 89831]\n",
      "new_token_input_ids_list[0]: [2, 651, 165609, 235292, 714, 18949, 576, 573, 18457]\n",
      "new_token_input_ids_list[0]: [2, 651, 140994, 0, 0, 0, 0, 0, 0]\n",
      "new_token_input_ids_list[0]: [2, 74268, 591, 12905, 235275, 892, 41330, 235290, 1040]\n",
      "new_token_input_ids_list[0]: [2, 651, 8182, 6251, 576, 56635, 892, 41330, 235290]\n",
      "new_token_input_ids_list[0]: [2, 188729, 576, 573, 33336, 235292, 1993, 89831, 201546]\n",
      "new_token_input_ids_list[0]: [2, 651, 165609, 235292, 714, 18949, 576, 573, 18457, 234317]\n",
      "new_token_input_ids_list[0]: [2, 651, 140994, 0, 0, 0, 0, 0, 0, 0]\n",
      "new_token_input_ids_list[0]: [2, 74268, 591, 12905, 235275, 892, 41330, 235290, 1040, 235307]\n",
      "new_token_input_ids_list[0]: [2, 651, 8182, 6251, 576, 56635, 892, 41330, 235290, 1040]\n",
      "new_token_input_ids_list[0]: [2, 188729, 576, 573, 33336, 235292, 1993, 89831, 201546, 0]\n",
      "new_token_input_ids_list[0]: [2, 651, 165609, 235292, 714, 18949, 576, 573, 18457, 234317, 0]\n",
      "new_token_input_ids_list[0]: [2, 651, 140994, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "new_token_input_ids_list[0]: [2, 74268, 591, 12905, 235275, 892, 41330, 235290, 1040, 235307, 0]\n",
      "new_token_input_ids_list[0]: [2, 651, 8182, 6251, 576, 56635, 892, 41330, 235290, 1040, 235307]\n",
      "new_token_input_ids_list[0]: [2, 188729, 576, 573, 33336, 235292, 1993, 89831, 201546, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# inference with model\n",
    "import json\n",
    "# asins_small.json to be used for meta data matching\n",
    "json_file_asins = './data/asins_small.json'\n",
    "# json_file_asins = './data/meta_asins.json'\n",
    "with open(json_file_asins, \"r\") as file:\n",
    "    asin_dict = json.load(file)\n",
    "    \n",
    "# len(asin_dict) # 748224 for the full meta bag # 434236 after filtering out the ones with no title\n",
    "\n",
    "from transformers import TextStreamer, GenerationConfig\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "max_seq_length = 4096 # 8192 | Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "    \n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"outputs/model_05162024_022532\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "        \n",
    "prompt_template = \"<start_of_turn>user\\n{}<end_of_turn>\\n<start_of_turn>model\\n{}\"\n",
    "\n",
    "movie_title = \"Mighty Machines: Super Pack 4-disc set\"\n",
    "input = find_full_intention(full_data, movie_title) \n",
    "inputs = tokenizer(\n",
    "[\n",
    "    prompt_template.format(input, \"\"),    \n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "num_beams_parameter = 5\n",
    "custom_generation_config = GenerationConfig(\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    asin_dict=asin_dict,\n",
    "    tokenizer=tokenizer,\n",
    "    return_dict_in_generate=True,\n",
    "    output_scores=True,\n",
    "    # output_logits=True,\n",
    "    # do_sample=True,\n",
    "    early_stopping=True,\n",
    "    num_beams=num_beams_parameter, \n",
    "    num_return_sequences=num_beams_parameter,\n",
    "    max_new_tokens=70, # used to be 35, some movie title might be long\n",
    "    use_cache=True,\n",
    "    temperature=1,\n",
    "    num_beam_groups=5, # In this generation mode, `num_beams` should be divisible by `num_beam_groups`. `diversity_penalty` is not 0.0 or `num_beam_groups` is not 1, triggering group beam search. \n",
    "    diversity_penalty=0.9, # `diversity_penalty` should be greater than `0.0`, otherwise your groups will be identical.\n",
    ")\n",
    "\n",
    "outputs = model.generate(**inputs, generation_config=custom_generation_config)\n",
    "\n",
    "# check CUDA memory usage\n",
    "used_memory = round(torch.cuda.max_memory_allocated() / 1024 / 1024 / 1024, 3)\n",
    "# if used_memory close to 14GB, empty the cache\n",
    "if used_memory > 14.3:\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"CUDA memory usage is high. Cleared the cache.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frozen (Feature) [Blu-ray]\n",
      "tensor(-0.5890, device='cuda:0')\n",
      "The Hobbit: The Battle of the Five Armies\n",
      "tensor(-0.6652, device='cuda:0')\n",
      "Pirates of the Caribbean: On Stranger Tides\n",
      "tensor(-0.7024, device='cuda:0')\n",
      "The Secret Life of Pets [Blu-ray]\n",
      "tensor(-0.7856, device='cuda:0')\n",
      "The Martian\n",
      "tensor(-1.9584, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(outputs['sequences'])):\n",
    "    # print(tokenizer.batch_decode(outputs['sequences'][i], skip_special_tokens=True))\n",
    "    sequence = \"\".join(tokenizer.batch_decode(outputs['sequences'][i], skip_special_tokens=True))\n",
    "    sequence = sequence.split(\"model\\n\")[1]\n",
    "    print(sequence)\n",
    "    if num_beams_parameter == 1: print(outputs['scores'][-1][0][1]) # this is for num_beam = 1\n",
    "    else: print(outputs['sequences_scores'][i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

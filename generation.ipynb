{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# asins_small.json to be used for meta data matching\n",
    "json_file_asins = './data/asins_small.json'\n",
    "with open(json_file_asins, \"r\") as file:\n",
    "    asin_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded eval dataset from ./data/gemma_chat_eval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"Below is the previous historical purchases and reviews of the user:\\n```\\nItem title: Justified: The Complete Series \\n Item description: For six electrifying seasons, no crime series proved more combustible than the Peabody Award-winning Justified. At the explosive center of the action, Western-style, gun-slinging U.S. Marshal Raylan Givens (Timothy Olyphant) confronts murder, drugs, bank heists, mobsters, crime families, corrupt politicians and even his own tumultuous past – and never backs down. His ultimate adversary is the cunning, complex outlaw Boyd Crowder (Walter Goggins), but the real wild card is Ava Crowder (Joelle Carter), the mysterious woman torn between the two men and both sides of the law. From creator Graham Yost and based on legendary author Elmore Leonard’s crime novella “Fire in the Hole,” it all leads to a perfectly unexpected final showdown. \\n rating: 5.0 \\n review: Love this series....bought it n for my husband for his birthday-------\\n```\\nAnd here is the user's intention: I really enjoy intense, drama-filled series with great character development, surprise twists, and a stellar cast, so I'm looking for something similar to what I've watched before.\\nPlease infer the user's preference based on historical purchases and reviews along with the user's intention, and then recommend an item for this user. Please just give the title of the recommended item.\",\n",
       " 'Yellowstone: Season One[Blu-ray]')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read eval dataset from local\n",
    "from datasets import load_from_disk\n",
    "\n",
    "dataset_eval = load_from_disk(\"./data/gemma_chat_eval\")\n",
    "print(\"Loaded eval dataset from {}\".format(\"./data/gemma_chat_eval\"))\n",
    "\n",
    "index_i = 16\n",
    "dataset_eval[index_i]['input'], \\\n",
    "dataset_eval[index_i]['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth: Fast Gemma patching release 2024.4\n",
      "   \\\\   /|    GPU: Tesla T4. Max memory: 14.581 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.2.2. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = FALSE. Xformers = 0.0.25.post1. FA = False.\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using customized constraint logits processor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_token_input_ids_list[0]: [2]\n",
      "new_token_input_ids_list[0] size: 1\n",
      "new_token_input_ids_list[1]: [2]\n",
      "new_token_input_ids_list[1] size: 1\n",
      "new_token_input_ids_list[2]: [2]\n",
      "new_token_input_ids_list[2] size: 1\n",
      "new_token_input_ids_list[0]: [2, 58423]\n",
      "new_token_input_ids_list[0] size: 2\n",
      "new_token_input_ids_list[1]: [2, 58423]\n",
      "new_token_input_ids_list[1] size: 2\n",
      "new_token_input_ids_list[2]: [2, 58423]\n",
      "new_token_input_ids_list[2] size: 2\n",
      "new_token_input_ids_list[0]: [2, 58423, 8920]\n",
      "new_token_input_ids_list[0] size: 3\n",
      "new_token_input_ids_list[1]: [2, 58423, 8920]\n",
      "new_token_input_ids_list[1] size: 3\n",
      "new_token_input_ids_list[2]: [2, 58423, 8920]\n",
      "new_token_input_ids_list[2] size: 3\n",
      "new_token_input_ids_list[0]: [2, 58423, 8920, 235292]\n",
      "new_token_input_ids_list[0] size: 4\n",
      "new_token_input_ids_list[1]: [2, 58423, 8920, 235292]\n",
      "new_token_input_ids_list[1] size: 4\n",
      "new_token_input_ids_list[2]: [2, 58423, 8920, 235292]\n",
      "new_token_input_ids_list[2] size: 4\n",
      "new_token_input_ids_list[0]: [2, 58423, 8920, 235292, 13316]\n",
      "new_token_input_ids_list[0] size: 5\n",
      "new_token_input_ids_list[1]: [2, 58423, 8920, 235292, 13316]\n",
      "new_token_input_ids_list[1] size: 5\n",
      "new_token_input_ids_list[2]: [2, 58423, 8920, 235292, 13316]\n",
      "new_token_input_ids_list[2] size: 5\n",
      "new_token_input_ids_list[0]: [2, 58423, 8920, 235292, 13316, 235248]\n",
      "new_token_input_ids_list[0] size: 6\n",
      "new_token_input_ids_list[1]: [2, 58423, 8920, 235292, 13316, 235248]\n",
      "new_token_input_ids_list[1] size: 6\n",
      "new_token_input_ids_list[2]: [2, 58423, 8920, 235292, 13316, 235248]\n",
      "new_token_input_ids_list[2] size: 6\n",
      "new_token_input_ids_list[0]: [2, 58423, 8920, 235292, 13316, 235248, 235310]\n",
      "new_token_input_ids_list[0] size: 7\n",
      "new_token_input_ids_list[1]: [2, 58423, 8920, 235292, 13316, 235248, 235310]\n",
      "new_token_input_ids_list[1] size: 7\n",
      "new_token_input_ids_list[2]: [2, 58423, 8920, 235292, 13316, 235248, 235310]\n",
      "new_token_input_ids_list[2] size: 7\n",
      "new_token_input_ids_list[0]: [2, 58423, 8920, 235292, 13316, 235248, 235310, 0]\n",
      "new_token_input_ids_list[0] size: 8\n",
      "new_token_input_ids_list[1]: [2, 58423, 8920, 235292, 13316, 235248, 235310, 0]\n",
      "new_token_input_ids_list[1] size: 8\n",
      "new_token_input_ids_list[2]: [2, 58423, 8920, 235292, 13316, 235248, 235310, 0]\n",
      "new_token_input_ids_list[2] size: 8\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "probability tensor contains either `inf`, `nan` or element < 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 57\u001b[0m\n\u001b[1;32m     33\u001b[0m custom_generation_config \u001b[38;5;241m=\u001b[39m GenerationConfig(\n\u001b[1;32m     34\u001b[0m     bos_token_id\u001b[38;5;241m=\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mbos_token_id,\n\u001b[1;32m     35\u001b[0m     eos_token_id\u001b[38;5;241m=\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39meos_token_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# diversity_penalty=0.3,\u001b[39;00m\n\u001b[1;32m     50\u001b[0m )\n\u001b[1;32m     52\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(\n\u001b[1;32m     53\u001b[0m [\n\u001b[1;32m     54\u001b[0m     prompt_template\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m),    \n\u001b[1;32m     55\u001b[0m ], return_tensors \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 57\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_generation_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(outputs)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(outputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msequences\u001b[39m\u001b[38;5;124m'\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "File \u001b[0;32m/opt/conda/envs/unsloth_env/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/unsloth_env/lib/python3.10/site-packages/unsloth/models/llama.py:976\u001b[0m, in \u001b[0;36m_wrap_fast_inference.<locals>._fast_generate\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39minference_mode\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fast_generate\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    975\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautocast(device_type \u001b[38;5;241m=\u001b[39m device_type, dtype \u001b[38;5;241m=\u001b[39m dtype):\n\u001b[0;32m--> 976\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/unsloth_env/lib/python3.10/site-packages/peft/peft_model.py:1190\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.generate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1189\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m-> 1190\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1192\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/envs/unsloth_env/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/unsloth_env/lib/python3.10/site-packages/transformers/generation/utils.py:1708\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1700\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1701\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1702\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   1703\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1704\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1705\u001b[0m     )\n\u001b[1;32m   1707\u001b[0m     \u001b[38;5;66;03m# 14. run beam sample\u001b[39;00m\n\u001b[0;32m-> 1708\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_beam_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeam_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1716\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1717\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1718\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1719\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1720\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGROUP_BEAM_SEARCH:\n\u001b[1;32m   1723\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   1724\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   1725\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1726\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1732\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   1733\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/unsloth_env/lib/python3.10/site-packages/transformers/generation/utils.py:3601\u001b[0m, in \u001b[0;36mGenerationMixin._beam_sample\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   3597\u001b[0m next_token_scores \u001b[38;5;241m=\u001b[39m next_token_scores\u001b[38;5;241m.\u001b[39mview(batch_size, num_beams \u001b[38;5;241m*\u001b[39m vocab_size)\n\u001b[1;32m   3599\u001b[0m probs \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(next_token_scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 3601\u001b[0m next_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3602\u001b[0m next_token_scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mgather(next_token_scores, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, next_tokens)\n\u001b[1;32m   3604\u001b[0m next_token_scores, _indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msort(next_token_scores, descending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: probability tensor contains either `inf`, `nan` or element < 0"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    from transformers import TextStreamer, GenerationConfig\n",
    "    from unsloth import FastLanguageModel\n",
    "    \n",
    "    max_seq_length = 4096 # 8192 | Choose any! We auto support RoPE Scaling internally!\n",
    "    dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "    load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "    \n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name = \"outputs/model_04242024_090830/\", # YOUR MODEL YOU USED FOR TRAINING\n",
    "        max_seq_length = max_seq_length,\n",
    "        dtype = dtype,\n",
    "        load_in_4bit = load_in_4bit,\n",
    "    )\n",
    "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "    \n",
    "prompt_template = \"<start_of_turn>user\\n{}<end_of_turn>\\n<start_of_turn>model\\n{}\"\n",
    "\n",
    "input = dataset_eval[index_i]['input']\n",
    "# input = dataset_eval[index_i]['input'] + \"\\n Please also explain yourself in one sentence or two, why the user might be interested in your recommended item.\"\n",
    "# input = \"Hello, I am looking for a movie that will make me feel happy and excited. I love action movies with a lot of suspense and thrill. I also enjoy movies with a lot of drama and romance. Can you recommend a movie that will make me feel happy and excited? And please explain why you recommend this movie.\"\n",
    "# input= \"Below is the previous historical purchases and reviews of the user:\\n```\\nItem title: One Step Behind \\n Item description: A dangerous man awakes in the care of a mysterious woman. Once the pieces of his past fall into place, he's faced with the stark choice of accepting his new found love or becoming the man he once was. \\n rating: 4.0 \\n review: Nice Hard Boiled Indie! Plenty of Bad Guys, Femme Fatales and one Big Bad Ass Reluctant Hero! If you like old school Film Noir -  more specifically Hard Boiled - you'll enjoy this little indie film. It reminded me a lot of the Coen Brother's BLOOD SIMPLE and another desert noir from the 90s starring Nick Cage RED ROCK WEST. It has that same pace and flavor to it and it pays of at the end. Well done!-------\\nItem title: Untouched \\n Item description: This legal drama explores the life-changing effects a secret abortion has on Mitch Thomas. A town startled by an infant found murdered in a dumpster, stirs Mitch, the reluctant attorney, conflicted by the love he lost, to unveil his haunting secret. \\n rating: 4.0 \\n review: Nice courtroom drama with it's heart in the right place. Beautifully shot and written, this is an intriguing story with a bittersweet ending. Really enjoyed it!-------\\nItem title: The Man In The Silo \\n Item description: A successful business man wakes up to find himself in a dilapidated grain silo, he must reconnect the dots of his traumatized memory to discover the truth of how he ended up there. \\n rating: 5.0 \\n review: This is a beautiful film full of great cinematic storytelling plus a classic re-hash of the Bernard Herman's Vertigo Score. Being a Hitchcock fan, I can honestly say that this is a true HITCHCOCKIAN film - which we hear a lot but hardly ever see. You can tell the film was made with so much attention to detail and passion by the great cinematography, transitions, acting, pace, acting and editing - and everything works together to achieve a great visual art piece. But don't get me wrong, it is also super exciting and entertaining as the film keeps you guessing from beginning to end. It is full of intrigue and suspense - and it is haunting. I highly recommend THE MAN IN THE SILO and I can almost guarantee you haven't seen anything like it!-------\\n```\\nAnd here is the user's intention: I really enjoy indie films with strong storytelling and emotional depth, so I'm looking for a movie that will steal my heart and make me want to fall in love all over again.\\nPlease infer the user's preference based on historical purchases and reviews along with the user's intention, and then recommend an item for this user and provide its description.\"\n",
    "# input = \"hello, can you recommend me a random movie? Maybe a romantic one? And please describe the reason why you recommend this movie.\"\n",
    "\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    # \"### Input:\\n{inputs}\\n\\n### Response:{outputs}\".format(inputs= input, outputs= \"\"),\n",
    "    # \"{inputs}\".format(inputs= input),\n",
    "    prompt_template.format(input, \"\"),    \n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "num_beams_parameter = 3\n",
    "custom_generation_config = GenerationConfig(\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    asin_dict=asin_dict,\n",
    "    tokenizer=tokenizer,\n",
    "    return_dict_in_generate=True,\n",
    "    output_scores=True,\n",
    "    # output_logits=True,\n",
    "    do_sample=True,\n",
    "    num_beams=num_beams_parameter, \n",
    "    num_return_sequences=num_beams_parameter,\n",
    "    max_new_tokens=96,\n",
    "    use_cache=True,\n",
    "    temperature=1,\n",
    "    # num_beam_groups=num_beams_parameter,\n",
    "    # diversity_penalty=0.3,\n",
    ")\n",
    "\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    prompt_template.format(input, \"\"),    \n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, generation_config=custom_generation_config)\n",
    "print(outputs)\n",
    "print(tokenizer.batch_decode(outputs['sequences'], skip_special_tokens=True))\n",
    "# outputs['scores'] is the tuple of probabilty distributions at every time step.\n",
    "\n",
    "# text_streamer = TextStreamer(tokenizer)\n",
    "# _ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 2048, num_beams=1, do_sample=True, generation_config=custom_generation_config, use_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 321])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs['sequences'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '', 'user', '\\n', 'Below', ' is', ' the', ' previous', ' historical', ' purchases', ' and', ' reviews', ' of', ' the', ' user', ':', '\\n', '```', '\\n', 'Item', ' title', ':', ' Jus', 'tified', ':', ' The', ' Complete', ' Series', ' ', '\\n', ' Item', ' description', ':', ' For', ' six', ' elect', 'rifying', ' seasons', ',', ' no', ' crime', ' series', ' proved', ' more', ' combustible', ' than', ' the', ' Peabody', ' Award', '-', 'winning', ' Jus', 'tified', '.', ' At', ' the', ' explosive', ' center', ' of', ' the', ' action', ',', ' Western', '-', 'style', ',', ' gun', '-', 'sling', 'ing', ' U', '.', 'S', '.', ' Marshal', ' Ray', 'lan', ' Gi', 'vens', ' (', 'Timothy', ' Oly', 'phant', ')', ' confronts', ' murder', ',', ' drugs', ',', ' bank', ' he', 'ists', ',', ' mob', 'sters', ',', ' crime', ' families', ',', ' corrupt', ' politicians', ' and', ' even', ' his', ' own', ' tumultuous', ' past', ' –', ' and', ' never', ' backs', ' down', '.', ' His', ' ultimate', ' adversary', ' is', ' the', ' cunning', ',', ' complex', ' outlaw', ' Boyd', ' Crow', 'der', ' (', 'Walter', ' Gog', 'gins', '),', ' but', ' the', ' real', ' wild', ' card', ' is', ' Ava', ' Crow', 'der', ' (', 'Jo', 'elle', ' Carter', '),', ' the', ' mysterious', ' woman', ' torn', ' between', ' the', ' two', ' men', ' and', ' both', ' sides', ' of', ' the', ' law', '.', ' From', ' creator', ' Graham', ' Y', 'ost', ' and', ' based', ' on', ' legendary', ' author', ' El', 'more', ' Leonard', '’', 's', ' crime', ' novella', ' “', 'Fire', ' in', ' the', ' Hole', ',”', ' it', ' all', ' leads', ' to', ' a', ' perfectly', ' unexpected', ' final', ' showdown', '.', ' ', '\\n', ' rating', ':', ' ', '5', '.', '0', ' ', '\\n', ' review', ':', ' Love', ' this', ' series', '....', 'bought', ' it', ' n', ' for', ' my', ' husband', ' for', ' his', ' birthday', '-------', '\\n', '```', '\\n', 'And', ' here', ' is', ' the', ' user', \"'\", 's', ' intention', ':', ' I', ' really', ' enjoy', ' intense', ',', ' drama', '-', 'filled', ' series', ' with', ' great', ' character', ' development', ',', ' surprise', ' twists', ',', ' and', ' a', ' stellar', ' cast', ',', ' so', ' I', \"'\", 'm', ' looking', ' for', ' something', ' similar', ' to', ' what', ' I', \"'\", 've', ' watched', ' before', '.', '\\n', 'Please', ' infer', ' the', ' user', \"'\", 's', ' preference', ' based', ' on', ' historical', ' purchases', ' and', ' reviews', ' along', ' with', ' the', ' user', \"'\", 's', ' intention', ',', ' and', ' then', ' recommend', ' an', ' item', ' for', ' this', ' user', '.', ' Please', ' just', ' give', ' the', ' title', ' of', ' the', ' recommended', ' item', '.', '', '\\n', '', 'model', '\\n', 'Jus', 'tified', ':', ' Season', ' ', '4', '']\n",
      "\n",
      "['', '', 'user', '\\n', 'Below', ' is', ' the', ' previous', ' historical', ' purchases', ' and', ' reviews', ' of', ' the', ' user', ':', '\\n', '```', '\\n', 'Item', ' title', ':', ' Jus', 'tified', ':', ' The', ' Complete', ' Series', ' ', '\\n', ' Item', ' description', ':', ' For', ' six', ' elect', 'rifying', ' seasons', ',', ' no', ' crime', ' series', ' proved', ' more', ' combustible', ' than', ' the', ' Peabody', ' Award', '-', 'winning', ' Jus', 'tified', '.', ' At', ' the', ' explosive', ' center', ' of', ' the', ' action', ',', ' Western', '-', 'style', ',', ' gun', '-', 'sling', 'ing', ' U', '.', 'S', '.', ' Marshal', ' Ray', 'lan', ' Gi', 'vens', ' (', 'Timothy', ' Oly', 'phant', ')', ' confronts', ' murder', ',', ' drugs', ',', ' bank', ' he', 'ists', ',', ' mob', 'sters', ',', ' crime', ' families', ',', ' corrupt', ' politicians', ' and', ' even', ' his', ' own', ' tumultuous', ' past', ' –', ' and', ' never', ' backs', ' down', '.', ' His', ' ultimate', ' adversary', ' is', ' the', ' cunning', ',', ' complex', ' outlaw', ' Boyd', ' Crow', 'der', ' (', 'Walter', ' Gog', 'gins', '),', ' but', ' the', ' real', ' wild', ' card', ' is', ' Ava', ' Crow', 'der', ' (', 'Jo', 'elle', ' Carter', '),', ' the', ' mysterious', ' woman', ' torn', ' between', ' the', ' two', ' men', ' and', ' both', ' sides', ' of', ' the', ' law', '.', ' From', ' creator', ' Graham', ' Y', 'ost', ' and', ' based', ' on', ' legendary', ' author', ' El', 'more', ' Leonard', '’', 's', ' crime', ' novella', ' “', 'Fire', ' in', ' the', ' Hole', ',”', ' it', ' all', ' leads', ' to', ' a', ' perfectly', ' unexpected', ' final', ' showdown', '.', ' ', '\\n', ' rating', ':', ' ', '5', '.', '0', ' ', '\\n', ' review', ':', ' Love', ' this', ' series', '....', 'bought', ' it', ' n', ' for', ' my', ' husband', ' for', ' his', ' birthday', '-------', '\\n', '```', '\\n', 'And', ' here', ' is', ' the', ' user', \"'\", 's', ' intention', ':', ' I', ' really', ' enjoy', ' intense', ',', ' drama', '-', 'filled', ' series', ' with', ' great', ' character', ' development', ',', ' surprise', ' twists', ',', ' and', ' a', ' stellar', ' cast', ',', ' so', ' I', \"'\", 'm', ' looking', ' for', ' something', ' similar', ' to', ' what', ' I', \"'\", 've', ' watched', ' before', '.', '\\n', 'Please', ' infer', ' the', ' user', \"'\", 's', ' preference', ' based', ' on', ' historical', ' purchases', ' and', ' reviews', ' along', ' with', ' the', ' user', \"'\", 's', ' intention', ',', ' and', ' then', ' recommend', ' an', ' item', ' for', ' this', ' user', '.', ' Please', ' just', ' give', ' the', ' title', ' of', ' the', ' recommended', ' item', '.', '', '\\n', '', 'model', '\\n', 'Jus', 'tified', ':', ' Season', ' ', '4', '']\n",
      "\n",
      "['', '', 'user', '\\n', 'Below', ' is', ' the', ' previous', ' historical', ' purchases', ' and', ' reviews', ' of', ' the', ' user', ':', '\\n', '```', '\\n', 'Item', ' title', ':', ' Jus', 'tified', ':', ' The', ' Complete', ' Series', ' ', '\\n', ' Item', ' description', ':', ' For', ' six', ' elect', 'rifying', ' seasons', ',', ' no', ' crime', ' series', ' proved', ' more', ' combustible', ' than', ' the', ' Peabody', ' Award', '-', 'winning', ' Jus', 'tified', '.', ' At', ' the', ' explosive', ' center', ' of', ' the', ' action', ',', ' Western', '-', 'style', ',', ' gun', '-', 'sling', 'ing', ' U', '.', 'S', '.', ' Marshal', ' Ray', 'lan', ' Gi', 'vens', ' (', 'Timothy', ' Oly', 'phant', ')', ' confronts', ' murder', ',', ' drugs', ',', ' bank', ' he', 'ists', ',', ' mob', 'sters', ',', ' crime', ' families', ',', ' corrupt', ' politicians', ' and', ' even', ' his', ' own', ' tumultuous', ' past', ' –', ' and', ' never', ' backs', ' down', '.', ' His', ' ultimate', ' adversary', ' is', ' the', ' cunning', ',', ' complex', ' outlaw', ' Boyd', ' Crow', 'der', ' (', 'Walter', ' Gog', 'gins', '),', ' but', ' the', ' real', ' wild', ' card', ' is', ' Ava', ' Crow', 'der', ' (', 'Jo', 'elle', ' Carter', '),', ' the', ' mysterious', ' woman', ' torn', ' between', ' the', ' two', ' men', ' and', ' both', ' sides', ' of', ' the', ' law', '.', ' From', ' creator', ' Graham', ' Y', 'ost', ' and', ' based', ' on', ' legendary', ' author', ' El', 'more', ' Leonard', '’', 's', ' crime', ' novella', ' “', 'Fire', ' in', ' the', ' Hole', ',”', ' it', ' all', ' leads', ' to', ' a', ' perfectly', ' unexpected', ' final', ' showdown', '.', ' ', '\\n', ' rating', ':', ' ', '5', '.', '0', ' ', '\\n', ' review', ':', ' Love', ' this', ' series', '....', 'bought', ' it', ' n', ' for', ' my', ' husband', ' for', ' his', ' birthday', '-------', '\\n', '```', '\\n', 'And', ' here', ' is', ' the', ' user', \"'\", 's', ' intention', ':', ' I', ' really', ' enjoy', ' intense', ',', ' drama', '-', 'filled', ' series', ' with', ' great', ' character', ' development', ',', ' surprise', ' twists', ',', ' and', ' a', ' stellar', ' cast', ',', ' so', ' I', \"'\", 'm', ' looking', ' for', ' something', ' similar', ' to', ' what', ' I', \"'\", 've', ' watched', ' before', '.', '\\n', 'Please', ' infer', ' the', ' user', \"'\", 's', ' preference', ' based', ' on', ' historical', ' purchases', ' and', ' reviews', ' along', ' with', ' the', ' user', \"'\", 's', ' intention', ',', ' and', ' then', ' recommend', ' an', ' item', ' for', ' this', ' user', '.', ' Please', ' just', ' give', ' the', ' title', ' of', ' the', ' recommended', ' item', '.', '', '\\n', '', 'model', '\\n', 'Jus', 'tified', ':', ' Season', ' ', '4', '']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(outputs['sequences'])):\n",
    "    print(tokenizer.batch_decode(outputs['sequences'][i], skip_special_tokens=True))\n",
    "    print(\"\")\n",
    "# print(tokenizer.batch_decode(outputs['sequences'][0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# outputs['scores'][-1]\n",
    "# check every token's probability distribution, if there is a token with a positive probability\n",
    "for i, token in enumerate(outputs['scores'][-1][0]):\n",
    "    if token != -math.inf:\n",
    "        print(f\"index: {i}, Score: {token}\")\n",
    "        print(tokenizer.decode(i))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read eval dataset from local\n",
    "from datasets import load_from_disk\n",
    "\n",
    "dataset_eval = load_from_disk(\"./data/gemma_chat_eval\")\n",
    "print(\"Loaded eval dataset from {}\".format(\"./data/gemma_chat_eval\"))\n",
    "\n",
    "index_i = 16\n",
    "dataset_eval[index_i]['input'], \\\n",
    "dataset_eval[index_i]['output']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

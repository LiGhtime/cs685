{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29205"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "# asins_small.json to be used for meta data matching\n",
    "json_file_asins = './data/asins_small.json'\n",
    "# json_file_asins = './data/meta_asins.json'\n",
    "with open(json_file_asins, \"r\") as file:\n",
    "    asin_dict = json.load(file)\n",
    "    \n",
    "len(asin_dict) # 748224 for the full meta bag # 434236 after filtering out the ones with no title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Spitfire Grill'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asin_dict['B005TZGJBA'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded eval dataset from ./data/gemma_chat_eval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"Below is the previous historical purchases and reviews of the user:\\n```\\nItem title: Justified: The Complete Series \\n Item description: For six electrifying seasons, no crime series proved more combustible than the Peabody Award-winning Justified. At the explosive center of the action, Western-style, gun-slinging U.S. Marshal Raylan Givens (Timothy Olyphant) confronts murder, drugs, bank heists, mobsters, crime families, corrupt politicians and even his own tumultuous past – and never backs down. His ultimate adversary is the cunning, complex outlaw Boyd Crowder (Walter Goggins), but the real wild card is Ava Crowder (Joelle Carter), the mysterious woman torn between the two men and both sides of the law. From creator Graham Yost and based on legendary author Elmore Leonard’s crime novella “Fire in the Hole,” it all leads to a perfectly unexpected final showdown. \\n rating: 5.0 \\n review: Love this series....bought it n for my husband for his birthday-------\\n```\\nAnd here is the user's intention: I really enjoy intense, drama-filled series with great character development, surprise twists, and a stellar cast, so I'm looking for something similar to what I've watched before.\\nPlease infer the user's preference based on historical purchases and reviews along with the user's intention, and then recommend an item for this user. Please just give the title of the recommended item.\",\n",
       " 'Yellowstone: Season One[Blu-ray]')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read eval dataset from local\n",
    "from datasets import load_from_disk\n",
    "\n",
    "dataset_eval = load_from_disk(\"./data/gemma_chat_eval\")\n",
    "print(\"Loaded eval dataset from {}\".format(\"./data/gemma_chat_eval\"))\n",
    "\n",
    "index_i = 16\n",
    "dataset_eval[index_i]['input'], \\\n",
    "dataset_eval[index_i]['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth: Fast Gemma patching release 2024.4\n",
      "   \\\\   /|    GPU: Tesla T4. Max memory: 14.581 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.2.2. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = FALSE. Xformers = 0.0.25.post1. FA = False.\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "Using customized constraint logits processor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating trie...\n",
      "new_token_input_ids_list[0]: [2]\n",
      "new_token_input_ids_list[0] size: 1\n",
      "new_token_input_ids_list[0]: [2, 58423]\n",
      "new_token_input_ids_list[0] size: 2\n",
      "new_token_input_ids_list[0]: [2, 58423, 8920]\n",
      "new_token_input_ids_list[0] size: 3\n",
      "new_token_input_ids_list[0]: [2, 58423, 8920, 235292]\n",
      "new_token_input_ids_list[0] size: 4\n",
      "new_token_input_ids_list[0]: [2, 58423, 8920, 235292, 13316]\n",
      "new_token_input_ids_list[0] size: 5\n",
      "new_token_input_ids_list[0]: [2, 58423, 8920, 235292, 13316, 235248]\n",
      "new_token_input_ids_list[0] size: 6\n",
      "new_token_input_ids_list[0]: [2, 58423, 8920, 235292, 13316, 235248, 235310]\n",
      "new_token_input_ids_list[0] size: 7\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextStreamer, GenerationConfig\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "max_seq_length = 4096 # 8192 | Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "    \n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"outputs/model_04242024_090830/\", # YOUR MODEL YOU USED FOR TRAINING\n",
    "    # model_name = \"unsloth/gemma-2b-it-bnb-4bit\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "        \n",
    "prompt_template = \"<start_of_turn>user\\n{}<end_of_turn>\\n<start_of_turn>model\\n{}\"\n",
    "\n",
    "input = dataset_eval[index_i]['input']\n",
    "# input = dataset_eval[index_i]['input'] + \"\\n Please also explain yourself in one sentence or two, why the user might be interested in your recommended item.\"\n",
    "# input = \"Hello, I am looking for a movie that will make me feel happy and excited. I love action movies with a lot of suspense and thrill. I also enjoy movies with a lot of drama and romance. Can you recommend a movie that will make me feel happy and excited? And please explain why you recommend this movie.\"\n",
    "# input= \"Below is the previous historical purchases and reviews of the user:\\n```\\nItem title: One Step Behind \\n Item description: A dangerous man awakes in the care of a mysterious woman. Once the pieces of his past fall into place, he's faced with the stark choice of accepting his new found love or becoming the man he once was. \\n rating: 4.0 \\n review: Nice Hard Boiled Indie! Plenty of Bad Guys, Femme Fatales and one Big Bad Ass Reluctant Hero! If you like old school Film Noir -  more specifically Hard Boiled - you'll enjoy this little indie film. It reminded me a lot of the Coen Brother's BLOOD SIMPLE and another desert noir from the 90s starring Nick Cage RED ROCK WEST. It has that same pace and flavor to it and it pays of at the end. Well done!-------\\nItem title: Untouched \\n Item description: This legal drama explores the life-changing effects a secret abortion has on Mitch Thomas. A town startled by an infant found murdered in a dumpster, stirs Mitch, the reluctant attorney, conflicted by the love he lost, to unveil his haunting secret. \\n rating: 4.0 \\n review: Nice courtroom drama with it's heart in the right place. Beautifully shot and written, this is an intriguing story with a bittersweet ending. Really enjoyed it!-------\\nItem title: The Man In The Silo \\n Item description: A successful business man wakes up to find himself in a dilapidated grain silo, he must reconnect the dots of his traumatized memory to discover the truth of how he ended up there. \\n rating: 5.0 \\n review: This is a beautiful film full of great cinematic storytelling plus a classic re-hash of the Bernard Herman's Vertigo Score. Being a Hitchcock fan, I can honestly say that this is a true HITCHCOCKIAN film - which we hear a lot but hardly ever see. You can tell the film was made with so much attention to detail and passion by the great cinematography, transitions, acting, pace, acting and editing - and everything works together to achieve a great visual art piece. But don't get me wrong, it is also super exciting and entertaining as the film keeps you guessing from beginning to end. It is full of intrigue and suspense - and it is haunting. I highly recommend THE MAN IN THE SILO and I can almost guarantee you haven't seen anything like it!-------\\n```\\nAnd here is the user's intention: I really enjoy indie films with strong storytelling and emotional depth, so I'm looking for a movie that will steal my heart and make me want to fall in love all over again.\\nPlease infer the user's preference based on historical purchases and reviews along with the user's intention, and then recommend an item for this user and provide its description.\"\n",
    "# input = \"hello, can you recommend me a random movie? Maybe a romantic one? And please describe the reason why you recommend this movie.\"\n",
    "\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    # \"### Input:\\n{inputs}\\n\\n### Response:{outputs}\".format(inputs= input, outputs= \"\"),\n",
    "    # \"{inputs}\".format(inputs= input),\n",
    "    prompt_template.format(input, \"\"),    \n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "num_beams_parameter = 1\n",
    "custom_generation_config = GenerationConfig(\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    asin_dict=asin_dict,\n",
    "    tokenizer=tokenizer,\n",
    "    return_dict_in_generate=True,\n",
    "    output_scores=True,\n",
    "    # output_logits=True,\n",
    "    do_sample=True,\n",
    "    # early_stopping=True,\n",
    "    num_beams=num_beams_parameter, \n",
    "    num_return_sequences=num_beams_parameter,\n",
    "    max_new_tokens=35,\n",
    "    use_cache=True,\n",
    "    temperature=1,\n",
    "    # num_beam_groups=num_beams_parameter, # In this generation mode, `num_beams` should be divisible by `num_beam_groups`. `diversity_penalty` is not 0.0 or `num_beam_groups` is not 1, triggering group beam search. \n",
    "    # diversity_penalty=0.5, # `diversity_penalty` should be greater than `0.0`, otherwise your groups will be identical.\n",
    ")\n",
    "\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    prompt_template.format(input, \"\"),    \n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, generation_config=custom_generation_config)\n",
    "# print(outputs)\n",
    "# print(tokenizer.batch_decode(outputs['sequences'], skip_special_tokens=True))\n",
    "# outputs['scores'] is the tuple of probabilty distributions at every time step.\n",
    "\n",
    "# text_streamer = TextStreamer(tokenizer)\n",
    "# _ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 2048, num_beams=1, do_sample=True, generation_config=custom_generation_config, use_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences\n",
      "scores\n",
      "past_key_values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 321]),)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for k, items in outputs.items():\n",
    "    print(k)\n",
    "outputs['sequences'].size(), \\\n",
    "    # outputs['sequences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Justified: Season 4\n",
      "tensor(9.3906, device='cuda:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(outputs['sequences'])):\n",
    "    # print(tokenizer.batch_decode(outputs['sequences'][i], skip_special_tokens=True))\n",
    "    sequence = \"\".join(tokenizer.batch_decode(outputs['sequences'][i], skip_special_tokens=True))\n",
    "    sequence = sequence.split(\"model\\n\")[1]\n",
    "    print(sequence)\n",
    "    if num_beams_parameter == 1: print(outputs['scores'][-1][0][1]) # this is for num_beam = 1\n",
    "    else: print(outputs['sequences_scores'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.eval.metrics import ReciprocalRank\n",
    "\n",
    "metric = ReciprocalRank(k=1)\n",
    "metric.update(torch.tensor([[0, 0.1, 0.6, 0.3], [0, 0, 1, 0]]), torch.tensor([2, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# outputs['scores'][-1]\n",
    "# check every token's probability distribution, if there is a token with a positive probability\n",
    "for i, token in enumerate(outputs['scores'][-1][0]):\n",
    "    if token != -math.inf:\n",
    "        print(f\"index: {i}, Score: {token}\")\n",
    "        print(tokenizer.decode(i))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read eval dataset from local\n",
    "from datasets import load_from_disk\n",
    "\n",
    "dataset_eval = load_from_disk(\"./data/gemma_chat_eval\")\n",
    "print(\"Loaded eval dataset from {}\".format(\"./data/gemma_chat_eval\"))\n",
    "\n",
    "index_i = 16\n",
    "dataset_eval[index_i]['input'], \\\n",
    "dataset_eval[index_i]['output']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
